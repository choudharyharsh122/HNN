{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"ml tqdm/4.66.2-GCCcore-13.2.0\")\n",
    "from tqdm import tqdm\n",
    "os.system(\"ml PyTorch/2.2.1-foss-2023b-CUDA-12.4.0\")\n",
    "import torch\n",
    "import torch.nn as nn   \n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.autograd.functional import jacobian\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "import optuna\n",
    "import csv\n",
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "import argparse\n",
    "import distutils.util\n",
    "import tracemalloc\n",
    "import psutil\n",
    "import torch.utils.benchmark as benchmark\n",
    "import gc\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s', handlers=[logging.StreamHandler(sys.stdout)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HamiltonianNN(nn.Module):\n",
    "\n",
    "    def __init__(self, model_specs):\n",
    "        super(HamiltonianNN, self).__init__()\n",
    "\n",
    "        # Create a list of linear layers based on layer_sizes\n",
    "        layer_sizes = model_specs[0]\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout_layers = nn.ModuleList()\n",
    "        self.RANDOM_SEED = 0\n",
    "        for i in range(len(layer_sizes) - 2):  # All layers except the last one\n",
    "            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1], bias=True))\n",
    "\n",
    "            self.dropout_layers.append(nn.Dropout(p=0.2))\n",
    "        \n",
    "        # Last layer without bias\n",
    "        self.layers.append(nn.Linear(layer_sizes[-2], layer_sizes[-1], bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            x = layer(x)\n",
    "            x = torch.tanh(x)\n",
    "            if i < len(self.dropout_layers):\n",
    "                x = self.dropout_layers[i](x)\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "    \n",
    "    def _apply_xavier_init(self):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_ode(y_tensor, args, kargs):\n",
    "\n",
    "    model = args[0]\n",
    "    i = kargs[0]\n",
    "        \n",
    "    with torch.enable_grad():\n",
    "\n",
    "        #y = y_tensor.clone().detach().requires_grad_(True)\n",
    "\n",
    "        y = y_tensor.requires_grad_(True)\n",
    "\n",
    "        h = model(y)\n",
    "\n",
    "    \n",
    "        grad_h = torch.autograd.grad(outputs=h.sum(), inputs=y, create_graph=True, allow_unused=True)[0]\n",
    "        #print(\"grad h: \", grad_h)\n",
    "        dq_dt = grad_h[:, 1]\n",
    "        dp_dt = -grad_h[:, 0]\n",
    "\n",
    "    return torch.stack((dq_dt, dp_dt), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def adjoint_ode(lam, args, kargs):\n",
    "\n",
    "#     (model, y_values) = args\n",
    "#     batch_size = y_values.shape[0]\n",
    "#     (i,) = kargs\n",
    "#     br_i = y_values.shape[2]//2\n",
    "\n",
    "#     y_tensor = y_values[:,i,:].clone().detach().requires_grad_(True)\n",
    "    \n",
    "#     h = model(y_tensor)\n",
    "\n",
    "#     # Compute first-order derivatives ∇H = [∂H/∂q, ∂H/∂p]\n",
    "#     grad_h = torch.autograd.grad(outputs=h.sum(), inputs=y_tensor, create_graph=True, retain_graph=True)[0]  # Shape: [batch_size, 2n]\n",
    "\n",
    "#     # Compute second-order derivatives\n",
    "#     J_H = torch.zeros(batch_size, 2*br_i, 2*br_i)  # Initialize Jacobian matrix\n",
    "\n",
    "#     for i in range(2 * br_i):\n",
    "#         if i<br_i:\n",
    "#             grad_i = torch.autograd.grad(outputs=grad_h[:, br_i+i], inputs=y_tensor, grad_outputs=torch.ones_like(grad_h[:, br_i+i]), create_graph=True, retain_graph=True)[0]\n",
    "#         else:\n",
    "#             grad_i = torch.autograd.grad(outputs=-grad_h[:, i-br_i], inputs=y_tensor, grad_outputs=torch.ones_like(-grad_h[:, i-br_i]), create_graph=True, retain_graph=True)[0]\n",
    "#         J_H[:, i, :] = grad_i  # Assign row-wise\n",
    "    \n",
    "#     lam_tensor = lam.clone().detach().unsqueeze(2)\n",
    "\n",
    "\n",
    "#     lam_dot = - (torch.bmm(J_H, lam_tensor)).squeeze()\n",
    "\n",
    "#     return lam_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_gradients(flattened_gradients, original_shapes):\n",
    "    reshaped_gradients = []\n",
    "    start = 0\n",
    "    for shape in original_shapes:\n",
    "        size = torch.prod(torch.tensor(shape)).item()  # Calculate the number of elements in this shape\n",
    "        end = start + size\n",
    "        reshaped_gradients.append(flattened_gradients[start:end].reshape(shape))\n",
    "        start = end\n",
    "    return reshaped_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rk2_step(dyn, y, dt, dynamics, args, kargs):\n",
    "    h = dt\n",
    "    i = kargs[0]\n",
    "    q, p = y[:, 0], y[:, 1]\n",
    "\n",
    "    y = torch.stack((q, p), dim=-1)  # Shape: (batch_size, 2)\n",
    "\n",
    "    #print(q.shape)\n",
    "\n",
    "    dy1 = dynamics(y, args, kargs)\n",
    "    q1 = q + 0.5 * dy1[:, 0] * h\n",
    "    p1 = p + 0.5 * dy1[:, 1] * h\n",
    "\n",
    "    y1 = torch.stack((q1, p1), dim=-1)  # Shape: (batch_size, 2)\n",
    "    dy2 = dynamics(y1, args, kargs)\n",
    "\n",
    "    q_new = q + dy2[:, 0] * h\n",
    "    p_new = p + dy2[:, 1] * h\n",
    "    return torch.stack((q_new, p_new), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_step(y, dt, dynamics, iterations, y_init, args, kargs):\n",
    "    h = dt\n",
    "    br_i = y.shape[1] // 2\n",
    "    q, p = y[:, 0:br_i], y[:, br_i:2 * br_i]\n",
    "    \n",
    "    y_init_concat = torch.cat((y_init[:, 0:br_i], y_init[:, br_i:2*br_i]), dim=-1)  # Shape [batch, 2]\n",
    "    f_init = dynamics(y_init_concat, args, kargs)  # Compute dynamics at initial point\n",
    "    \n",
    "    q_new = q + 0.5 * h * f_init[:, 0:br_i]  # Shape [batch, 1]\n",
    "    p_new = p + 0.5 * h * f_init[:, br_i:2*br_i]  # Shape [batch, 1]\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        mid_q = 0.5 * (q + q_new)  # Shape [batch, q_shape]\n",
    "        mid_p = 0.5 * (p + p_new)  # Shape [batch, p_shape]\n",
    "        \n",
    "        mid_concat = torch.cat((mid_q, mid_p), dim=-1)  # Ensure [batch, 2*q_shape]\n",
    "        f_mid = dynamics(mid_concat, args, kargs)  # Compute dynamics at midpoint\n",
    "        \n",
    "        q_new = q + h * f_mid[:, 0:br_i]  # Shape [batch, q_shape]\n",
    "        p_new = p + h * f_mid[:, br_i:2*br_i]  # Shape [batch, p_shape]\n",
    "\n",
    "    return torch.cat((q_new, p_new), dim=-1)  # Final shape [batch, 2*q_shape]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sv_step(dyn, y, dt, dynamics, iterations, y_init, args, kargs):\n",
    "    h = dt\n",
    "    q, p = y[:, 0], y[:, 1]\n",
    "    i = kargs[0]\n",
    "\n",
    "    p_half = p + 0.5 * h * dynamics(torch.stack((q, y_init[:, 1]), dim=-1), args, kargs)[:, 1]\n",
    "    for _ in range(iterations):\n",
    "        p_half = p + 0.5 * h * dynamics(torch.stack((q, p_half), dim=-1), args, kargs)[:, 1]\n",
    "\n",
    "    q_half = q + 0.5 * h * dynamics(torch.stack((y_init[:, 0], p_half), dim=-1), args, kargs)[:, 0]\n",
    "    for _ in range(iterations):\n",
    "        q_half = q + 0.5 * h * dynamics(torch.stack((q_half, p), dim=-1), args, kargs)[:, 0]\n",
    "\n",
    "    q_new = q + h * dynamics(torch.stack((q_half, p_half), dim=-1), args, kargs)[:, 0]\n",
    "    p_new = p_half + 0.5 * h * dynamics(torch.stack((q_new, p_half), dim=-1), args, kargs)[:, 1]\n",
    "\n",
    "    return torch.stack((q_new, p_new), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_ivp_custom(dynamics, dyn, y0_batch, t_span, dt, args, iters):\n",
    "    #t = torch.arange(0, T, dt)\n",
    "    batch_size = y0_batch.shape[0]\n",
    "    t0, t1 = t_span\n",
    "    if t0 > t1:\n",
    "        dt = -dt\n",
    "    num_steps = int((t1 - t0) / dt) + 1\n",
    "    #y0_batch = noisy_obs[:, 0, :]\n",
    "    ys_batch = [y0_batch]\n",
    "    #print(y0_batch.shape)\n",
    "\n",
    "\n",
    "    for i in range(1, num_steps):\n",
    "        #y = noisy_obs[:, i-1, :]  # Use the noisy observation at the current step\n",
    "        y = ys_batch[-1]\n",
    "        y_ = rk2_step(dyn, y, dt, dynamics, args, kargs=(i,))\n",
    "        y_next = sv_step(dyn, y, dt, dynamics, iters, y_, args, kargs=(i,))\n",
    "        #print(y_next.requires_grad)\n",
    "        ys_batch.append(y_next)\n",
    "        #print(y_next.shape)\n",
    "    ys_batch = torch.stack(ys_batch, dim=1)\n",
    "    #print(ys_batch.requires_grad)\n",
    "    return ys_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_grad(model, y_t, lambda_t, batch_size):\n",
    "\n",
    "#     integral_values = []\n",
    "#     batch_size = lambda_t.shape[0]\n",
    "#     br_i = y_t.shape[1]//2\n",
    "\n",
    "#     y_tensor = y_t.clone().detach().requires_grad_(True).to(y_t.device)\n",
    "    \n",
    "#     # Perform forward pass\n",
    "#     h = model(y_tensor)\n",
    "    \n",
    "#     # Compute gradients of model output w.r.t y_tensor\n",
    "#     grad_h = torch.autograd.grad(outputs=h.sum(), inputs=y_tensor,\n",
    "#                                  create_graph=True, retain_graph=True, allow_unused=True)[0]\n",
    "    \n",
    "#     grad_w_p = torch.autograd.grad(outputs=grad_h[:, br_i:2*br_i], inputs=model.parameters(), \n",
    "#                                    grad_outputs=lambda_t[:, 0:br_i],\n",
    "#                                    create_graph=True, retain_graph=True, allow_unused=True)\n",
    "    \n",
    "#     grad_w_q = torch.autograd.grad(outputs=grad_h[:, 0:br_i], inputs=model.parameters(), \n",
    "#                                    grad_outputs=lambda_t[:, br_i:2*br_i],\n",
    "#                                    create_graph=True, retain_graph=True, allow_unused=True)\n",
    "    \n",
    "#     if grad_w_p is not None:\n",
    "#         grad_w_p = torch.cat([p_grad.flatten() for p_grad in grad_w_p]).unsqueeze(0)\n",
    "#         grad_w_p = grad_w_p.expand(batch_size, -1) / batch_size\n",
    "    \n",
    "#     if grad_w_q is not None:\n",
    "#         grad_w_q = torch.cat([p_grad.flatten() for p_grad in grad_w_q]).unsqueeze(0)\n",
    "#         grad_w_q = grad_w_q.expand(batch_size, -1) / batch_size\n",
    "    \n",
    "#     grad_w_combined = grad_w_p - grad_w_q\n",
    "\n",
    "#     model.zero_grad()\n",
    "    \n",
    "#     return grad_w_combined.mean(dim=0)  # avg over batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def backward(dynamics, pred, lambda_data, solver, dt, shooting_segment_length, number_of_shooting_segments, args, iters):\n",
    "#     #t1, t0 = t_span\n",
    "#     shooting_nodes = [lambda_data[:, i*(shooting_segment_length) - 1, :] for i in range(number_of_shooting_segments, 0 ,-1)]\n",
    "#     segments = []\n",
    "#     cont_errors = []\n",
    "#     y_batch = args[1]\n",
    "#     num_steps = shooting_segment_length*number_of_shooting_segments\n",
    "#     batch_size = lambda_data.shape[0]\n",
    "#     model = args[0]\n",
    "\n",
    "#     num_params = sum(p.numel() for p in model.parameters())\n",
    "#     grad_result = torch.zeros(num_params, device=lambda_data.device)\n",
    "\n",
    "#     grad_result += (-dt / 2) * calculate_grad(model, y_batch[:,-1,:], lambda_data[:,-1,:], batch_size)\n",
    "    \n",
    "#     for seg in range(number_of_shooting_segments, 0, -1):\n",
    "#         lam_seg = shooting_nodes[seg-1]\n",
    "#         #seg_states = [lam_seg]\n",
    "        \n",
    "#         for j in range(1, shooting_segment_length):\n",
    "#             step_index = seg * shooting_segment_length - j - 1\n",
    "#             if pred:\n",
    "#                 y_ = rk2_step(lam_seg, dt, dynamics, args, kargs=(step_index,))\n",
    "#             else:\n",
    "#                 y_ = lambda_data[:, step_index, :]\n",
    "            \n",
    "#             if solver==\"im\":\n",
    "#                 lam_next = im_step(lam_seg, dt, dynamics, iters, y_, args, kargs=(step_index,))\n",
    "#             elif solver==\"sv\":\n",
    "#                 lam_next = sv_step(lam_seg, dt, dynamics, iters, y_, args, kargs=(step_index,))\n",
    "            \n",
    "#             #print(\"Heyyoo:\",y_batch[:,num_steps-step_index-1,:].shape, lam_next.shape)\n",
    "            \n",
    "#             #current_grad = calculate_grad(model, y_batch[:,num_steps-step_index-1,:], lam_next, batch_size)\n",
    "\n",
    "#             current_grad = calculate_grad(model, y_batch[:,step_index,:], lam_next, batch_size)\n",
    "\n",
    "#             #print(\"step Index: \", step_index)\n",
    "\n",
    "#             # if step_index==num_steps-1:\n",
    "#             #     grad_result += (-dt / 2) * (current_grad)\n",
    "#             if step_index==0:\n",
    "#                 grad_result += (-dt / 2) * (current_grad)\n",
    "#             else:\n",
    "#                 grad_result += (-dt) * (current_grad)\n",
    "            \n",
    "#             lam_seg = lam_next\n",
    "#     return grad_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_gt(gt_data, dt_solve, dt_gt):\n",
    "    downsample_factor = int(dt_solve / dt_gt)\n",
    "    return gt_data[:, ::downsample_factor, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_gt(gt_data, dt_solve, dt_gt):\n",
    "    downsample_factor = int(dt_solve / dt_gt)\n",
    "    return gt_data[:, ::downsample_factor, :]\n",
    "\n",
    "\n",
    "def load_data(datafolder, dynamics, dt_solve, dt_gt):\n",
    "\n",
    "    noisy_train_path = \"../data/\"+str(datafolder)+\"/noisy_\"+str(dynamics)+\"_train.pt\"\n",
    "    noisy_val_path = \"../data/\"+str(datafolder)+\"/noisy_\"+str(dynamics)+\"_val.pt\"\n",
    "    noisy_test_path = \"../data/\"+str(datafolder)+\"/noisy_\"+str(dynamics)+\"_test.pt\"\n",
    "\n",
    "    train_path = \"../data/\"+str(datafolder)+\"/\"+str(dynamics)+\"_train.pt\"\n",
    "    val_path = \"../data/\"+str(datafolder)+\"/\"+str(dynamics)+\"_val.pt\"\n",
    "    test_path = \"../data/\"+str(datafolder)+\"/\"+str(dynamics)+\"_test.pt\"\n",
    "\n",
    "    noisy_train_trajectories = torch.load(noisy_train_path).to(device)\n",
    "    noisy_val_trajectories = torch.load(noisy_val_path).to(device)\n",
    "\n",
    "    true_train_trajectories = torch.load(train_path).to(device)\n",
    "    true_val_trajectories = torch.load(val_path).to(device)\n",
    "\n",
    "\n",
    "    # Downsample ground truth data according to dt_solve\n",
    "    noisy_train_trajectories = downsample_gt(noisy_train_trajectories, dt_solve, dt_gt)\n",
    "    true_train_trajectories = downsample_gt(true_train_trajectories, dt_solve, dt_gt)\n",
    "\n",
    "\n",
    "    noisy_val_trajectories = downsample_gt(noisy_val_trajectories, dt_solve, dt_gt)\n",
    "    true_val_trajectories = downsample_gt(true_val_trajectories, dt_solve, dt_gt)\n",
    "\n",
    "\n",
    "    return noisy_train_trajectories, noisy_val_trajectories, true_train_trajectories, true_val_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(model, noisy_train_traj, noisy_val_traj, true_train_traj, true_val_traj, dt_gt, dt_solve, param_vals):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    num_epochs = 1\n",
    "\n",
    "    learning_rate = param_vals[\"lr\"]\n",
    "    \n",
    "    train_batch_size = param_vals[\"train_batch_size\"]\n",
    "    val_batch_size = param_vals[\"val_batch_size\"]\n",
    "    sim_len = param_vals[\"sim_len\"]\n",
    "    sims = param_vals[\"sims\"]\n",
    "    learning_rate = param_vals[\"lr\"]\n",
    "    train_batch_size = param_vals[\"train_batch_size\"]\n",
    "    val_batch_size = param_vals[\"val_batch_size\"]\n",
    "    T = param_vals[\"t_final\"]\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "\n",
    "    train_dataset = TensorDataset(noisy_train_traj, true_train_traj)\n",
    "    val_dataset = TensorDataset(noisy_val_traj, true_val_traj)\n",
    "\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "    val_data_loader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=True)\n",
    "\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    alpha = 1e-4\n",
    "    peak_memory = 0\n",
    "    # Training loop\n",
    "    #print(\"Julian Time: \", )\n",
    "    print(f\"Params: Train size {noisy_train_traj.shape}, Val size {noisy_val_traj.shape}, Sim length {T} sec\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        logging.info(f\"Progress: Step {epoch+1}\")\n",
    "        \n",
    "        torch.cuda.empty_cache()  # If running on CUDA, clears memory cache (not needed for CPU)\n",
    "        torch.autograd.set_detect_anomaly(True)  # Detect if anything is breaking computation graph\n",
    "\n",
    "\n",
    "        for batch in train_data_loader:\n",
    "            y_noisy_batch, y_true_batch = batch\n",
    "            y_noisy_batch = y_noisy_batch.to(device)\n",
    "            y_true_batch = y_true_batch.to(device)\n",
    "\n",
    "            #pq0_batch = torch.tensor(y_true_batch[:, 0, :], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "\n",
    "            pq0_batch = torch.tensor([[1.0, 0.0]], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "            tracemalloc.start()\n",
    "\n",
    "            y_pred_batch = solve_ivp_custom(forward_ode, \"forward\", pq0_batch, (0, T), dt_solve, args=(model,), iters=5)\n",
    "\n",
    "            #loss = y_pred_batch[:, -1, 0].sum()\n",
    "            \n",
    "            loss = criterion(y_pred_batch[:,:,0], y_true_batch[:,:,0]) + criterion(y_pred_batch[:,:,1], y_true_batch[:,:,1])\n",
    "            #lamb = torch.autograd.grad(loss, y_pred_batch, retain_graph=True)[0]\n",
    "            #y_pred_batch = y_pred_batch.detach()\n",
    "            #process = psutil.Process(os.getpid())  # Get current process\n",
    "            #mem_before = process.memory_info().rss  # Memory in bytes\n",
    "            #process = psutil.Process()\n",
    "            #loss.backward()\n",
    "\n",
    "            #gc.collect()  # Clear Python garbage\n",
    "\n",
    "            #mem_before = process.memory_info().rss  # Get memory before\n",
    "\n",
    "            # Retain the graph so we can call backward multiple times\n",
    "            loss.backward()\n",
    "\n",
    "            #gc.collect()  # Clear garbage again\n",
    "            #mem_after = process.memory_info().rss\n",
    "\n",
    "            _, peak_memory = tracemalloc.get_traced_memory()\n",
    "            tracemalloc.stop()\n",
    "\n",
    "            #print(f\"Peak Memory Usage: {peak_memory:.2f} MB\")\n",
    "\n",
    "            #peak_memory = benchmark.Timer(stmt=\"loss.backward(retain_graph=True)\", globals={\"loss\": loss}).blocked_autorange()\n",
    "\n",
    "            # Print the result\n",
    "\n",
    "            \n",
    "\n",
    "            #mem_after = torch.cuda.memory_allocated() if torch.cuda.is_available() else torch.cuda.memory_reserved()\n",
    "\n",
    "            #print(\"after:\", mem_after)\n",
    "\n",
    "            #mem_after = process.memory_info().rss  # Memory after backprop\n",
    "\n",
    "            #peak_memory = (mem_after - mem_before) / (1024**2)  # Convert to MB\n",
    "\n",
    "            #_, peak_memory = tracemalloc.get_traced_memory()\n",
    "            #tracemalloc.stop()\n",
    "\n",
    "            #grads = backward(adjoint_ode, pred, lamb, solver, -dt_solve, sim_len, sims, args=(model, y_pred_batch), iters=6)\n",
    "\n",
    "            #lambda_pred_batch = lambda_pred_batch.flip(1)\n",
    "\n",
    "            #grads = calculate_integral(model, y_pred_batch, T, lambda_pred_batch)\n",
    "\n",
    "            #Reshape the gradients to match the model parameters\n",
    "            # start_idx = 0\n",
    "            # for param in model.parameters():\n",
    "            #     param_shape = param.shape\n",
    "            #     param_size = param.numel()\n",
    "            #     param_grad = grads[start_idx:start_idx + param_size].reshape(param_shape)\n",
    "            #     param.grad = param_grad.clone().detach()\n",
    "            #     start_idx += param_size\n",
    "\n",
    "            # # Update the model parameters using the optimizer\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute loss\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        average_train_loss = total_loss / (train_batch_size)\n",
    "        train_losses.append(average_train_loss)\n",
    "\n",
    "        print(f'Epoch {epoch}/{num_epochs}, Train Loss: {total_loss/len(train_data_loader)}')\n",
    "        scheduler.step(total_loss/len(train_data_loader))\n",
    "\n",
    "        # Validation loop\n",
    "        \n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Log the time taken\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Objective function took {elapsed_time:.2f} seconds to complete\")\n",
    "    \n",
    "    return elapsed_time, peak_memory, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial:  0\n",
      "Params: Train size torch.Size([512, 4, 2]), Val size torch.Size([512, 4, 2]), Sim length 0.03 sec\n",
      "2025-03-18 23:08:59,133 - Progress: Step 1\n",
      "Epoch 0/1, Train Loss: 11.567575454711914\n",
      "Objective function took 2.59 seconds to complete\n",
      "Trial:  1\n",
      "Params: Train size torch.Size([512, 8, 2]), Val size torch.Size([512, 8, 2]), Sim length 0.07 sec\n",
      "2025-03-18 23:09:01,726 - Progress: Step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choudhar/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([512, 4])) that is different to the input size (torch.Size([1, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/choudhar/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([512, 8])) that is different to the input size (torch.Size([1, 8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1, Train Loss: 11.553638458251953\n",
      "Objective function took 6.06 seconds to complete\n",
      "Trial:  2\n",
      "Params: Train size torch.Size([512, 12, 2]), Val size torch.Size([512, 12, 2]), Sim length 0.11 sec\n",
      "2025-03-18 23:09:07,812 - Progress: Step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choudhar/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([512, 12])) that is different to the input size (torch.Size([1, 12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1, Train Loss: 11.519794464111328\n",
      "Objective function took 7.64 seconds to complete\n",
      "Trial:  3\n",
      "Params: Train size torch.Size([512, 16, 2]), Val size torch.Size([512, 16, 2]), Sim length 0.15 sec\n",
      "2025-03-18 23:09:15,472 - Progress: Step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choudhar/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([512, 16])) that is different to the input size (torch.Size([1, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1, Train Loss: 11.463944435119629\n",
      "Objective function took 10.04 seconds to complete\n",
      "Trial:  4\n",
      "Params: Train size torch.Size([512, 20, 2]), Val size torch.Size([512, 20, 2]), Sim length 0.19 sec\n",
      "2025-03-18 23:09:25,550 - Progress: Step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choudhar/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([512, 20])) that is different to the input size (torch.Size([1, 20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1, Train Loss: 11.374530792236328\n",
      "Objective function took 13.20 seconds to complete\n",
      "Trial:  5\n",
      "Params: Train size torch.Size([512, 24, 2]), Val size torch.Size([512, 24, 2]), Sim length 0.23 sec\n",
      "2025-03-18 23:09:38,788 - Progress: Step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choudhar/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([512, 24])) that is different to the input size (torch.Size([1, 24])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1, Train Loss: 11.246983528137207\n",
      "Objective function took 17.56 seconds to complete\n",
      "Trial:  6\n",
      "Params: Train size torch.Size([512, 28, 2]), Val size torch.Size([512, 28, 2]), Sim length 0.27 sec\n",
      "2025-03-18 23:09:56,407 - Progress: Step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choudhar/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([512, 28])) that is different to the input size (torch.Size([1, 28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1, Train Loss: 11.119200706481934\n",
      "Objective function took 20.43 seconds to complete\n",
      "Trial:  7\n",
      "Params: Train size torch.Size([512, 32, 2]), Val size torch.Size([512, 32, 2]), Sim length 0.31 sec\n",
      "2025-03-18 23:10:16,917 - Progress: Step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choudhar/anaconda3/envs/ghost/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([512, 32])) that is different to the input size (torch.Size([1, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1, Train Loss: 10.994285583496094\n",
      "Objective function took 18.55 seconds to complete\n",
      "Memory usage data saved to memory_usage_results.csv\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "\n",
    "    # # Parse command line arguments\n",
    "    # parser = argparse.ArgumentParser(description=\"Enter the simulation parameters\")\n",
    "    # parser.add_argument(\"--dynamics_name\", type=str, required=True, choices=[\"mass_spring\", \"double_well\", \"coupled_ho\", \"henon_heiles\"], help=\"The name of the dynamics function.\")\n",
    "    # parser.add_argument(\"--data_folder\", type=str, required=True, help=\"the ground truth data folder\")\n",
    "    # parser.add_argument(\"--gt_res\", type=float, required=True, help=\"the ground truth resolution/stepsize\")\n",
    "    # parser.add_argument(\"--hid_layers\", type=parse_hidden_layers, required=True,\n",
    "    #                     help=\"Hidden layers as a list of integers, e.g., [16,32,16]\")\n",
    "    # parser.add_argument(\"--solver_res\", type=float, required=True, help=\"The time step length for our solver(= k*gt_res where k is an integer)\")\n",
    "    # parser.add_argument(\"--noise_level\", type=float, required=False, default=0.0,\n",
    "    #                 help=\"The noise level (a float number from data_gen). Default is 0.0.\")\n",
    "    # parser.add_argument(\"--pred\", type=lambda x: bool(distutils.util.strtobool(x)), required=False, default=False, \n",
    "    #                 help=\"Boolean flag: True if you need a predictor step, False if you use GT (default: False)\")\n",
    "    # parser.add_argument(\"--num_sims\", type=int, required=False, default=1, help=\"The number of multi-shooting trajectories (default= 1 single shooting)\")\n",
    "    # parser.add_argument(\"--sim_len\", type=int, required=True, help=\"The forward simulation length of each trajectory for training.\")\n",
    "    # parser.add_argument(\"--solver\", type=str, required=False, default=\"im\", choices=[\"im\",\"sv\"])\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    \n",
    "dynamics_name = \"mass_spring\"\n",
    "data_folder = \"mass_spring_10\"\n",
    "dt_gt = 0.01\n",
    "hidden_layer_sizes = [16,32,16]\n",
    "dt_solve = 0.01\n",
    "noise_level = 0\n",
    "pred = True\n",
    "num_sims = 1\n",
    "sim_len = 7\n",
    "solver = \"im\"\n",
    "\n",
    "noisy_train, noisy_val, true_train, true_val = load_data(data_folder, dynamics_name, dt_gt, dt_solve)\n",
    "\n",
    "input_size = noisy_train.shape[2]\n",
    "output_size = 1\n",
    "\n",
    "train_set_len = int(noisy_train.shape[0])\n",
    "val_set_len = int(noisy_val.shape[0])\n",
    "\n",
    "layer_sizes = [input_size] + hidden_layer_sizes + [output_size]\n",
    "\n",
    "model_specs = (layer_sizes,)\n",
    "\n",
    "model = HamiltonianNN(model_specs).to(device) \n",
    "\n",
    "params_list = [{\"sim_len\":4, \"lr\":0.01, \"pred\":pred, \"solver\":solver,\n",
    "                    \"train_batch_size\":512, \"val_batch_size\":512, \"t_final\":0.03, \"sims\": num_sims}\n",
    "                ,{\"sim_len\":8, \"lr\":0.01, \"pred\":pred, \"solver\":solver,\n",
    "                    \"train_batch_size\":512, \"val_batch_size\":512, \"t_final\":0.07, \"sims\": num_sims}\n",
    "                  ,{\"sim_len\":12, \"lr\":0.01, \"pred\":pred, \"solver\":solver,\n",
    "                    \"train_batch_size\":512, \"val_batch_size\":512, \"t_final\":0.11, \"sims\": num_sims},\n",
    "                    {\"sim_len\":16, \"lr\":0.01, \"pred\":pred, \"solver\":solver,\n",
    "                    \"train_batch_size\":512, \"val_batch_size\":512, \"t_final\":0.15, \"sims\": num_sims},\n",
    "                    {\"sim_len\":20, \"lr\":0.01, \"pred\":pred, \"solver\":solver,\n",
    "                    \"train_batch_size\":512, \"val_batch_size\":512, \"t_final\":0.19, \"sims\": num_sims},\n",
    "                    {\"sim_len\":24, \"lr\":0.01, \"pred\":pred, \"solver\":solver,\n",
    "                    \"train_batch_size\":512, \"val_batch_size\":512, \"t_final\":0.23, \"sims\": num_sims},\n",
    "                    {\"sim_len\":28, \"lr\":0.01, \"pred\":pred, \"solver\":solver,\n",
    "                    \"train_batch_size\":512, \"val_batch_size\":512, \"t_final\":0.27, \"sims\": num_sims},\n",
    "                    {\"sim_len\":32, \"lr\":0.01, \"pred\":pred, \"solver\":solver,\n",
    "                    \"train_batch_size\":512, \"val_batch_size\":512, \"t_final\":0.31, \"sims\": num_sims}\n",
    "                    ]\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "models = []\n",
    "memory_usage_list = []\n",
    "time_list = []\n",
    "\n",
    "for i in range(len(params_list)):\n",
    "    \n",
    "    #start_ind = int(params_list[i][\"t_start\"]/dt_solve)\n",
    "    end_ind = params_list[i][\"sim_len\"]\n",
    "    train_batch_size = params_list[i][\"train_batch_size\"]\n",
    "    val_batch_size = params_list[i][\"val_batch_size\"]\n",
    "\n",
    "    print(\"Trial: \", str(i))\n",
    "    \n",
    "    elapsed_time, peak_memory, model = objective(model, noisy_train[0:train_batch_size, 0:end_ind, :],\n",
    "                                                noisy_val[0:val_batch_size, 0:end_ind, :], \n",
    "                                                true_train[0:train_batch_size, 0:end_ind, :], \n",
    "                                                true_val[0:val_batch_size, 0:end_ind, :], \n",
    "                                                dt_gt, dt_solve, params_list[i])\n",
    "    \n",
    "    memory_usage_list.append(peak_memory / (1024**2))\n",
    "    time_list.append(elapsed_time)\n",
    "\n",
    "\n",
    "# Save memory tracking results\n",
    "df = pd.DataFrame(zip(memory_usage_list, time_list), columns=['peak_memory', 'time'])\n",
    "df.to_csv(\"adjoint_memory_usage_results_2.csv\", index=False)\n",
    "print(\"Memory usage data saved to memory_usage_results.csv\")\n",
    "\n",
    "    #torch.save(model, f'../models/model_{i}_{dynamics_name}_{noise_level}_adjoint_{num_sims}_{sim_len}_{solver}.pt')\n",
    "    # df = pd.DataFrame({\n",
    "    # \"train_loss\": train_loss,\n",
    "    # \"val_loss\": val_loss\n",
    "    # })\n",
    "    # df.to_csv(f'output_{dynamics_name}_{noise_level}_adjoint_{num_sims}_{sim_len}_{solver}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ghost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
